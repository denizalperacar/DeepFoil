{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pickle\n",
    "from scipy.interpolate import CubicSpline\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/ariya/Desktop/github/Airfoil_Polar_prediction/aiaa_conference/xf/runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the folders\n",
    "af_files = [i.replace(directory, '') for i in glob(directory+'*')]\n",
    "files_dic, afs = {}, {}\n",
    "for i in range(len(af_files)):\n",
    "    af = af_files[i]\n",
    "    dir_name = '{}{}/'.format(directory,af)\n",
    "    afs[af] = [j for j in glob(dir_name+'*.af')]\n",
    "    files_dic[af] = [j for j in glob(dir_name+'*.polar')]\n",
    "\n",
    "# get the interpolation points -> predefined points\n",
    "#with open('interp.pickle', 'rb') as fid:\n",
    "#    interp = pickle.load(fid, encoding='latin1')\n",
    "interp = np.linspace(0, 1., 162).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the airfoils (optimized from 14s to 500ms)\n",
    "# use the interp to interpolate on x make data a series in y\n",
    "afs_passed = []\n",
    "af_data_dic = {}\n",
    "for af in af_files:\n",
    "    for files in afs[af]:\n",
    "        af_name = af\n",
    "        if af_name not in afs_passed:\n",
    "            afs_passed.append(af_name)\n",
    "            \n",
    "            with open(files,'r') as fid:\n",
    "                af_data = fid.readlines()\n",
    "                \n",
    "            af_name = af_data[0].replace('\\r\\n', '').replace(' ', '').lower()\n",
    "            x = []\n",
    "            y = []\n",
    "            for lines in range(1, len(af_data)):\n",
    "                line = af_data[lines].replace('\\r\\n', '').split()\n",
    "                x.append(float(line[0]))\n",
    "                y.append(float(line[1]))\n",
    "\n",
    "            x = np.array(x).reshape(1,-1)\n",
    "            y = np.array(y).reshape(1,-1)\n",
    "\n",
    "            # split the upper and lower surfaces\n",
    "            x_min = x.argmin()\n",
    "            x_up = x[0,0:x_min+1]\n",
    "            x_do = x[0,x_min:]\n",
    "            y_up = y[0,0:x_min+1]\n",
    "            y_do = y[0,x_min:]\n",
    "            \n",
    "            # remove x duplicates\n",
    "            x_up, index = np.unique(x_up, axis=0, return_index=True)\n",
    "            y_up = y_up[index].copy()\n",
    "            x_do, index = np.unique(x_do, axis=0, return_index=True)\n",
    "            y_do = y_do[index].copy()\n",
    "            \n",
    "            # get the interpolation points\n",
    "            int_min = interp.argmin()\n",
    "            x_up_int = interp\n",
    "            x_do_int = interp\n",
    "            # interpolate\n",
    "            #y_up_int = np.flip(np.interp(np.flip(x_up_int,0), np.flip(x_up, 0), np.flip(y_up,0)), 0)\n",
    "            #y_do_int = np.interp(x_do_int, x_do, y_do)\n",
    "            \n",
    "            y_up_int = np.flip(CubicSpline(x_up, y_up)(np.flip(x_up_int,0)), 0)\n",
    "            y_do_int = CubicSpline(x_do, y_do)(x_do_int)\n",
    "            \n",
    "            nn_input = np.concatenate((y_up_int.reshape(1,-1),np.flip(y_do_int).reshape(1,-1)), axis=1)\n",
    "            \n",
    "            af_data_dic[af_name] = {}\n",
    "            af_data_dic[af_name]['x'] = np.array(x).reshape(1,-1)\n",
    "            af_data_dic[af_name]['y'] = np.array(y).reshape(1,-1)\n",
    "            af_data_dic[af_name]['x_up'] = x_up.reshape(1,-1)\n",
    "            af_data_dic[af_name]['x_do'] = x_do.reshape(1,-1)\n",
    "            af_data_dic[af_name]['y_up'] = y_up.reshape(1,-1)\n",
    "            af_data_dic[af_name]['y_do'] = y_do.reshape(1,-1)\n",
    "            af_data_dic[af_name]['x_up_int'] = x_up_int.reshape(1,-1)\n",
    "            af_data_dic[af_name]['x_do_int'] = x_do_int.reshape(1,-1)\n",
    "            af_data_dic[af_name]['y_up_int'] = y_up_int.reshape(1,-1)\n",
    "            af_data_dic[af_name]['y_do_int'] = y_do_int.reshape(1,-1)\n",
    "            af_data_dic[af_name]['input'] = nn_input\n",
    "\n",
    "# save the results\n",
    "with open('tr_af_points.pickle', 'wb') as fid:\n",
    "    pickle.dump(af_data_dic, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate afs\n",
    "af_label = {name: num for num, name in enumerate(af_data_dic.keys())}\n",
    "label_af = {}\n",
    "for i in af_label.keys():\n",
    "    label_af[af_label[i]] = i\n",
    "with open('tr_af_labels.pickle', 'wb') as fid:\n",
    "    pickle.dump(af_label, fid)\n",
    "with open('tr_label_afs.pickle', 'wb') as fid:\n",
    "    pickle.dump(label_af, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get the polars data for each airfoil - 1081673 many data currently\n",
    "polars = []\n",
    "nn_input = []\n",
    "for af in af_files:\n",
    "    for files in files_dic[af]:\n",
    "        try:\n",
    "            with open(files, 'r') as fid:\n",
    "                polar = fid.readlines()\n",
    "            af_n = af_label[polar[3].replace('Calculated polar for:','').replace(' ', '').\n",
    "                          replace('\\r\\n', '').lower()]\n",
    "            re = float(files.split('/')[-1].split('_')[-1].replace('.polar', ''))\n",
    "\n",
    "            index = 0\n",
    "            for lines in range(len(polar)):\n",
    "                line = polar[lines].split()\n",
    "                try:\n",
    "                    if line[0] == 'alpha':\n",
    "                        index = lines\n",
    "                except:\n",
    "                    continue\n",
    "            for k in range(index+2, len(polar)):\n",
    "                l = polar[k].replace('\\r\\n', '').split()\n",
    "                cur_list = [af_n, re]\n",
    "                ll = [float(m) for m in l[:5]]\n",
    "                cur_list.extend(ll)\n",
    "                polars.append(cur_list)\n",
    "        except:\n",
    "            print(af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save, both as a dataframe and a pickle\n",
    "a = pd.DataFrame(polars, columns=['af', 're', 'a', 'cl', 'cd', 'cdp', 'cm'])\n",
    "a.to_csv('tr_raw_af_data.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore it\n",
    "with open('tr_polars.pickle', 'w') as fid:\n",
    "    pickle.dump(polars, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
